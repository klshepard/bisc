{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import settings \"\"\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib_settings import set_plot_settings, reset_plot_settings\n",
    "\n",
    "# Set the plot settings\n",
    "set_plot_settings()\n",
    "\n",
    "# import global variables\n",
    "from utils_ssep_global import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" load data, define static params \"\"\"\n",
    "# load bad channel\n",
    "bad_ch_idx_dir = f'{DATA_DIR}/1_bad_channels'\n",
    "bad_chs = np.load(f\"{bad_ch_idx_dir}/bad_ch_idx.npy\")\n",
    "\n",
    "# load downsampled data\n",
    "fs, Ts = FS/RS, TS*RS\n",
    "ds_data_dir = f'{DATA_DIR}/5_downsample'\n",
    "t = np.load(f\"{ds_data_dir}/t_{RS}.npy\")\n",
    "\n",
    "# SSEP index\n",
    "sep_idxs = np.where(np.logical_and(t > SEP_T0, t < SEP_T1))[0]\n",
    "\n",
    "# Baseline index\n",
    "baseline_idxs = np.where(np.logical_and(t > BASELINE_T0, t < BASELINE_T1))[0]\n",
    "\n",
    "# define \"z-score window\"\n",
    "# zscore_t0, zscore_t1 = BASELINE_T0, SEP_T1\n",
    "# zscore_idxs = np.where(np.logical_and(t > zscore_t0, t < zscore_t1))[0]\n",
    "\n",
    "zscored_data_dir = f'{DATA_DIR}/7_zscore'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sites = 5 # total number of stimulation locations\n",
    "stim_sites = [0, 1, 4, 2, 3] # re-order for plotting\n",
    "min_trial = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" load z-scored data \"\"\"\n",
    "zds_datas = [[] for _ in range(n_sites)]\n",
    "\n",
    "for idx, stim_site in enumerate(stim_sites):\n",
    "    fn_label = STIM_LABELS[stim_site].replace(\" \", \"_\").lower()\n",
    "\n",
    "    zds_segs = np.load(f\"{zscored_data_dir}/{fn_label}_ds_{RS}_zscore.npy\")\n",
    "    zds_datas[idx] = zds_segs # 256*Trial*time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" For each stim location, sort the data in terms of trial, ordering each trial \n",
    "    by the number of non-saturated channels \"\"\"\n",
    "\n",
    "for idx, zds_data in enumerate(zds_datas):\n",
    "    zds_data = np.transpose(zds_data, (1, 0, 2)) # trial*256*time\n",
    "\n",
    "    # iterate through trials, computing the number of non-saturated channels\n",
    "    good_ch_counts = np.zeros((zds_data.shape[0]))\n",
    "    for trial_idx, trial_data in enumerate(zds_data):\n",
    "        good_ch_counts[trial_idx] = np.sum(~np.isnan(trial_data[:,0]))\n",
    "\n",
    "    # sort\n",
    "    sorted_idx = np.argsort(-good_ch_counts)\n",
    "\n",
    "    # rearrange the original data in the order of non-sat. channels\n",
    "    zds_datas[idx] = zds_datas[idx][:,sorted_idx,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Input for tSNE and LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" sample 100 trials from each stimulation site \"\"\"\n",
    "sample_size = 100\n",
    "zds_subset = np.zeros((sample_size*n_sites, NCH, len(sep_idxs)))\n",
    "\n",
    "bad_chs = []\n",
    "for site_idx, zds_segs in enumerate(zds_datas):\n",
    "    zds_segs = np.transpose(zds_segs, (1, 0, 2)) # trial*256*time\n",
    "\n",
    "    sample_idxs = np.arange(0, sample_size)\n",
    "    offset_idx = site_idx*sample_size\n",
    "\n",
    "    zds_subset[offset_idx:offset_idx+sample_size,:,:] = zds_segs[:sample_size,:,sep_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" identify channels that are not consistently non-saturated (for all trials) \"\"\"\n",
    "for ch, ch_data in enumerate(np.transpose(zds_subset, (1, 0, 2))):\n",
    "    if np.any(np.isnan(ch_data)):\n",
    "        bad_chs.append(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" discard the identified channels \"\"\"\n",
    "common_chs = []\n",
    "for ch in range(256):\n",
    "    if not ch in bad_chs:\n",
    "        common_chs.append(ch)\n",
    "common_chs = np.array(common_chs)\n",
    "\n",
    "zds_subset = zds_subset[:,common_chs,:]\n",
    "print(len(common_chs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" true label. for both tSNE and LDA \"\"\"\n",
    "true_label = [[ii]*sample_size for ii in range(n_sites)]\n",
    "true_label = np.array(true_label).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" create a custom colormap \"\"\"\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Define the colors for the custom colormap\n",
    "color_list = [\n",
    "            #   (0, 0, 0, 0.7), # black\n",
    "            #   (1, 0.68, 0.26, 0.7), # orange\n",
    "              (1, 0, 0, 0.7), # red\n",
    "              (0.5, 0.2, 0.7, 0.7), # purple\n",
    "              (0, 0.5, 0.8, 0.7), # blue\n",
    "              (0, 0.5, 0, 0.7), # green\n",
    "              (0.5, 0.2, 0, 0.7) # brown\n",
    "              ] \n",
    "colors = []\n",
    "for stim_site in stim_sites:\n",
    "    colors.append(color_list[stim_site])\n",
    "\n",
    "# Create a ListedColormap using the defined colors\n",
    "custom_cmap = LinearSegmentedColormap.from_list('custom_colormap', colors, N=n_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def get_tsne(data, n_pca, exp_var_ratio, perplexity=30, tsne_seed=42, tsne_iter=1000):\n",
    "\n",
    "    # Step 1. PCA\n",
    "    if exp_var_ratio == 1:\n",
    "        pca_result = data\n",
    "    else:\n",
    "        # step A, identify the number of components that explains the given variance (exp_var_ratio)\n",
    "        pca = PCA(n_components=n_pca) # n_pca should be chosen to be a sufficiently large value\n",
    "        _ = pca.fit_transform(data)\n",
    "        var_ratio_cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "        n = np.argmax(var_ratio_cumsum > exp_var_ratio)\n",
    "        print(f'# of PCA components: {n}')\n",
    "    \n",
    "        # step B, re-do PCA with reduced number of components\n",
    "        pca2 = PCA(n_components=n)\n",
    "        pca_result = pca2.fit_transform(data)\n",
    "\n",
    "    # Step 2. TSNE\n",
    "    tsne = TSNE(n_components=2, perplexity=perplexity, n_iter=tsne_iter,\n",
    "                random_state=tsne_seed)\n",
    "    tsne_pca_result = tsne.fit_transform(pca_result)\n",
    "\n",
    "    return tsne_pca_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" tSNE \"\"\"\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
    "\n",
    "# tSNE\n",
    "tsne_result = get_tsne(zds_subset.reshape(zds_subset.shape[0], -1),\n",
    "                            n_pca=150, exp_var_ratio=0.8)\n",
    "\n",
    "# prediction vs. true using tSNE\n",
    "kmeans = KMeans(n_clusters=n_sites, random_state=42, n_init='auto')\n",
    "predicted_label =(kmeans.fit_predict(tsne_result))\n",
    "\n",
    "# metrics to characterize the clusters\n",
    "ARI = adjusted_rand_score(true_label, predicted_label)\n",
    "AMIS = adjusted_mutual_info_score(true_label, predicted_label)\n",
    "silhouette = silhouette_samples(tsne_result, predicted_label)\n",
    "\n",
    "sil_avg = np.mean(silhouette)\n",
    "sil_std = np.std(silhouette)\n",
    "print(f'{ARI=:.2f}, {AMIS=:.2f}')\n",
    "print(f'{sil_avg=:.2f}, {sil_std=:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" plot tSNE result \"\"\"\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "\n",
    "# title_str = f'nch={len(common_chs)}' , silhouette: {sil_avg:.2f}Â±{sil_std:.2f}'\n",
    "# ax.set_title(title_str)\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_xlabel('tSNE-1')\n",
    "ax.set_ylabel('tSNE-2')\n",
    "\n",
    "im = ax.scatter(tsne_result[:,0], tsne_result[:,1], c=true_label, cmap=custom_cmap)\n",
    "\n",
    "cbar_ax = fig.add_axes([0.93, 0.11, 0.04, 0.77]) # left, bottom, width, height\n",
    "cbar = fig.colorbar(im, cax = cbar_ax, ticks=[], orientation='vertical') \n",
    "custom_labels = ['MN', 'SL', 'SI', 'SS', 'SM']\n",
    "cbar.set_ticks([0.4, 1.2, 2, 2.8, 3.6])\n",
    "cbar.set_ticklabels(custom_labels, fontsize=16)\n",
    "cbar.ax.tick_params(length=0)  # Removing ticks\n",
    "cbar.ax.invert_yaxis()\n",
    "\n",
    "# save_dir = './figures/ssep/tSNE_LDA'\n",
    "# save_fn = f'tSNE'\n",
    "# plt.savefig(f\"{save_dir}./{save_fn}.svg\", bbox_inches='tight')\n",
    "# plt.savefig(f\"{save_dir}./{save_fn}.png\", bbox_inches='tight', dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Initialize LDA Classifier \"\"\"\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "def get_lda(data, true_label):\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "    lda_result = lda.fit_transform(data, true_label)\n",
    "    \n",
    "    return lda_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Build and Evaluate LDA Classifier \"\"\"\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "def get_lda_score(X, y, lda, cv):\n",
    "    accuracies = []\n",
    "    conf_matrices = []\n",
    "\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        lda.fit(X_train, y_train)\n",
    "        y_pred = lda.predict(X_test)\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred, normalize='true') * 100\n",
    "\n",
    "        accuracies.append(acc)\n",
    "        conf_matrices.append(conf_matrix)\n",
    "\n",
    "    return [np.array(accuracies), np.array(conf_matrices)]\n",
    "\n",
    "n_splits = 10\n",
    "cv_stratified_k_fold = StratifiedKFold(n_splits=10, shuffle=False)\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "X = zds_subset.reshape(zds_subset.shape[0], -1)\n",
    "y = true_label\n",
    "\n",
    "result = get_lda_score(X, y ,lda, cv_stratified_k_fold)\n",
    "accuracies, cms = result[0], result[1]\n",
    "\n",
    "# Display the results\n",
    "print(f\"Mean accuracy: {np.mean(accuracies)*100:.2f} +/- {np.std(accuracies)*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Plot Confusion Matrix \"\"\"\n",
    "import seaborn as sns\n",
    "# Visualize the mean confusion matrix using seaborn heatmap\n",
    "\n",
    "custom_labels = ['MN', 'SL', 'SI', 'SS', 'SM']\n",
    "\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "\n",
    "sns.heatmap(np.sum(cms, axis=0)/n_splits, annot=True, fmt=\".0f\", cmap=\"Blues\", vmin=0, vmax=100,\n",
    "            xticklabels=custom_labels, yticklabels=custom_labels, cbar=False)\n",
    "ax.set_xlabel('Predicted', fontsize=18)\n",
    "ax.set_ylabel('True', fontsize=18)\n",
    "ax.tick_params(labelsize=16)\n",
    "ax.tick_params(axis='both', which='both', length=0)  # Removing ticks\n",
    "\n",
    "# save_dir = './figures/ssep/tSNE_LDA'\n",
    "# save_fn = f'lda_cm'\n",
    "# plt.savefig(f\"{save_dir}./{save_fn}.svg\", bbox_inches='tight')\n",
    "# plt.savefig(f\"{save_dir}./{save_fn}.png\", bbox_inches='tight', dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "d955faee816db44f0a85e254d00ad008273b576d6dbe16759b0bc5b99bc5dcbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
