{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For synchronization between Pesaran Rig (PR) and BISC relay station,\n",
    "PR generated a psuedorandom bitstream that was captured by both systems.\n",
    "- BISC relay station captured the bitstream at 33.9kS/s.\n",
    "- PR had its own clock (precision down to ns, probably some NI component) for sampling\n",
    "this bitstream at around 1kS/s. Another thing to note about PR is that although the bitstream\n",
    "itself is captured at ~1kS/s, their time stamps are saved once every ~17 samples.\n",
    "\n",
    "To recover synchronization, this notebook does the following, in order.\n",
    "1. PR time stamps are interpolated to 1kS/s\n",
    "2. PR time stamp and bitstreams are upsampled to 33.9 kS/s\n",
    "3. Compute time lag between the two systems based on (auto)correlation\n",
    "\n",
    "Finally, there are time stamps associated with each video frame running at ~60Hz\n",
    "These time stamps are also captured by the PR clock (hence have the same unit and offset)\n",
    "4. Based on the time lag between the two systems, and treating t=0 as the beginning of BISC\n",
    "recording, appropriate offset is applied to these video frame time stamps and saved\n",
    "\n",
    "Additional Note:\n",
    "PR's clock and BISC clock are running independently (not synchronized), but this notebook\n",
    "does not correct for the \"clock drift\". Effect of drift is negligible since the lengths of\n",
    "recording are short (less than 2 min). Error due to drift is less than 3 ms. Note that video\n",
    "frames are captured at 60 Hz (16 ms)\n",
    "\n",
    "------------------------------\n",
    "\n",
    "Not really relevant, but ... this is an example of how PR's clock maps to real time.\n",
    "session 6: 143539\n",
    "real time - 14:35:46 <=> RIG timestamp 78272463418821\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib_settings import set_plot_settings, reset_plot_settings\n",
    "\n",
    "# Set the plot settings\n",
    "set_plot_settings()\n",
    "\n",
    "# import global variables\n",
    "from utils_motor_global import *\n",
    "from utils_motion import RIG_SYNC_HIGH, MOTION_IDX_DICT, read_sync_h5, correlate_custom\n",
    "from utils_motor_misc import list_files_with_keyword_extension\n",
    "\n",
    "sys.path.append(UTILS_DIR)\n",
    "from utils_mp import read_recdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pulses(rec_dir, rec_fname, use_tetrode, Ts, sel_invert=True):\n",
    "    _, pulses, _, _, _ = read_recdata(file_path=f'{rec_dir}/{rec_fname}',\n",
    "                                               use_tetrode=use_tetrode)\n",
    "\n",
    "    # print(f'bisc sync length: {len(pulses)*Ts:.1f} sec')\n",
    "    n = pulses.shape[0]\n",
    "    bisc_t = np.arange(n)*Ts\n",
    "    if sel_invert: # hardware configuration\n",
    "        bisc_sync = -1*pulses + 1 # invert\n",
    "\n",
    "    return bisc_t, bisc_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" save plot of sync pulses after synchronization. for sanity check \"\"\"\n",
    "sync_save_dir = f'{MOTION_DIR}/sync_img'\n",
    "if not os.path.exists(sync_save_dir):\n",
    "    os.makedirs(sync_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = 3\n",
    "h5name = f'test.tha.20230919.{session}'\n",
    "motion_dir = f'{RAW_MOTION_DIR}/{session:03}'\n",
    "sample_interval, sample_rate, received, rig_sync = read_sync_h5(motion_dir, h5name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in GOOD_SESSIONS:\n",
    "\n",
    "    \"\"\" Load sync pulses captured by BISC relay station \"\"\"\n",
    "    rec_dir = f\"{RAW_REC_DIR}/{session:03}\"\n",
    "    if not os.path.isdir(rec_dir):\n",
    "        continue\n",
    "    print(f'processing: session {session}')\n",
    "\n",
    "    assert len(os.listdir(rec_dir)) == 1\n",
    "    rec_fname =  os.listdir(rec_dir)[0]\n",
    "    bisc_t, bisc_sync = read_pulses(rec_dir, rec_fname, USE_TETRODE, TS)\n",
    "\n",
    "    \"\"\" Load sync pulses & their time stamps captured by PR \"\"\"\n",
    "    motion_dir = f'{RAW_MOTION_DIR}/{session:03}'\n",
    "    h5name = f'test.tha.20230919.{session}'\n",
    "\n",
    "    # received: Nx2 array. column 0: timestamp in ns, column 1: cumulative number of data points collected\n",
    "    # data: raw sample data (sync low: 0V, high: 5V)\n",
    "    sample_interval, sample_rate, received, rig_sync = read_sync_h5(motion_dir, h5name)\n",
    "    assert received[-1, 1] == rig_sync.shape[0] # total number of sync pulse data points\n",
    "\n",
    "    sample_interval = sample_interval*1e-9 # convert nanosec to sec\n",
    "\n",
    "    # convert to binary (sync does not need unrolling)\n",
    "    rig_sync = np.squeeze(rig_sync/RIG_SYNC_HIGH)\n",
    "    rig_sync = rig_sync.astype(np.int64) # not sure why 64-bit was allocated.. maybe for correlation computing later on?\n",
    "    rig_t = np.zeros_like(rig_sync)\n",
    "\n",
    "    \"\"\" 1. PR time stamps are interpolated to 1kS/s \"\"\"\n",
    "    rig_t_coarse = received[:, 0]\n",
    "    # number of samples per timestamp\n",
    "    npb = np.concatenate(([received[0,1]], np.diff(received[:,1])), dtype=int)\n",
    "\n",
    "    idx = 0\n",
    "    for n, t0, t1 in zip(npb, rig_t_coarse[:-1], rig_t_coarse[1:]):\n",
    "        rig_t[idx:idx + n] = t0 + ((t1-t0)/n)*np.linspace(0, n-1, n)\n",
    "        idx += n\n",
    "    n = npb[-1]\n",
    "    rig_t[idx:idx + n] = t1 + sample_interval*np.linspace(0, n-1, n)\n",
    "\n",
    "    # force to start at 0, and convert to sec\n",
    "    rig_t0 = rig_t[0].astype(np.int64)\n",
    "    rig_t -= rig_t0\n",
    "    rig_t = rig_t*1e-9\n",
    "    # rig_t = (rig_t - rig_t0)*1e-9\n",
    "\n",
    "    \"\"\" 2. PR time stamp and bitstreams are upsampled to 33.9 kS/s \"\"\"\n",
    "    n = int(rig_t[-1]*FS)\n",
    "    upsamp_t = np.arange(n)*TS\n",
    "    upsamp_sync = np.interp(upsamp_t, rig_t, rig_sync)\n",
    "\n",
    "    \"\"\" 3. Compute time lag between the two systems based on (auto)correlation \"\"\"\n",
    "    # Run Coarse Cross Correlation on Decimated Data\n",
    "    kdf = 100 # decimation factor\n",
    "    # correlate(a, v, mode='full). first element of the output: a[0]*v[-1]\n",
    "    coarse_corr = np.correlate(bisc_sync[::kdf]-0.5, upsamp_sync[::kdf]-0.5, mode='full')\n",
    "\n",
    "    i_coarse_shift = kdf*(np.argmax(coarse_corr))\n",
    "    t_coarse_shift = (i_coarse_shift - len(upsamp_t)) * TS\n",
    "\n",
    "    # Run Fine Cross Correlation\n",
    "    fine_corr = correlate_custom(bisc_sync-0.5, upsamp_sync-0.5,\n",
    "                                  i_coarse_shift-kdf, i_coarse_shift+kdf)\n",
    "\n",
    "    i_shift = (np.argmax(fine_corr))\n",
    "    # t_shift is the time lag between the two systems,\n",
    "    # from \"the first sync pulse captured on PR\" to \"the first sync pulse captured on BISC\"\n",
    "    t_shift = (i_shift - len(upsamp_t)) * TS\n",
    "\n",
    "    \"\"\" Save Plot of Time Lag Corrected Syncs \"\"\"\n",
    "    fig, ax = plt.subplots(3, 1, figsize=(10, 6), sharex=True)\n",
    "\n",
    "    ax[0].set_title(f'Session {session:03}\\n Rig, Before Upsample')\n",
    "    ax[0].plot(rig_t + t_shift, rig_sync)\n",
    "\n",
    "    ax[1].set_title('Rig, Upsampled')\n",
    "    ax[1].plot(upsamp_t + t_shift, upsamp_sync)\n",
    "\n",
    "    ax[2].set_title('BISC sync')\n",
    "    ax[2].plot(bisc_t, bisc_sync)\n",
    "\n",
    "    fig.savefig(f'{sync_save_dir}/{session:03}.png', bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "    \"\"\" Load Motion Data \"\"\"\n",
    "    # timestamps are in cam3 json. likelihood and position are in *.mat file\n",
    "    # load cam3 time\n",
    "    cam3_json_fname = f'troopa_230919_{session:03}_cam3.json'\n",
    "    with open(f'{motion_dir}/{cam3_json_fname}', 'r') as file:\n",
    "        cam3_t = np.array(json.load(file))\n",
    "\n",
    "    # Load motion v3 time point and correct it\n",
    "    motion_t = loadmat(f'{motion_dir}/rec_{session:03}_timestamp.mat')\n",
    "    motion_t = np.squeeze(motion_t['timestamps_rec'])\n",
    "\n",
    "    \"\"\" 4. Based on the time lag between the two systems, and treating t=0 as the beginning\n",
    "    of BISC recording, appropriate offset is applied to these time stamps and saved\"\"\"\n",
    "    # force first sample to be 0\n",
    "    motion_t -= motion_t[0]\n",
    "    # apply correction against the \"rig time\"\n",
    "    motion_t += (cam3_t[0] - rig_t0)*1e-9\n",
    "    # apply correction against BISC time\n",
    "    motion_t += t_shift \n",
    "\n",
    "    \"\"\" save \"\"\"\n",
    "    save_dir = f'{MOTION_DIR}/{session:03}'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    keys = [key for key in MOTION_IDX_DICT.keys() if key.startswith(f'{session:003}')]\n",
    "\n",
    "    # save time points over the whole session\n",
    "    np.save(f'{save_dir}/motion_t_{session:003}.npy', motion_t)\n",
    "    \n",
    "    # for key in keys:\n",
    "    #     (idx0, idx1) = MOTION_IDX_DICT[key]\n",
    "    #     if idx1 == -1: idx1 = len(motion_t)\n",
    "    \n",
    "    #     np.save(f'{save_dir}/pos_t_session_{key}.npy', motion_t[idx0:idx1])\n",
    "    #     print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### write assertion checks..!\n",
    "for session in GOOD_SESSIONS:\n",
    "    keys = [key for key in MOTION_IDX_DICT.keys() if key.startswith(f'{session:003}')]\n",
    "\n",
    "    dir0 = f'./motion_v3_postprocess_bak/{session:003}'\n",
    "    dir1 = f'./motion_v3_postprocess/{session:003}'\n",
    "    \n",
    "    t0 = np.load(f'{dir0}/motion_t.npy')\n",
    "    t1 = np.load(f'{dir1}/motion_t_{session:003}.npy')\n",
    "    assert np.array_equal(t0, t1)\n",
    "\n",
    "    for key in keys:\n",
    "        pass\n",
    "        # t_v3p0 = np.load(f'{dir0}/motion_t_v3p0_session_{key}.npy')\n",
    "        # t_v3p1 = np.load(f'{dir0}/motion_t_v3p1_session_{key}.npy')\n",
    "        # print(key)\n",
    "        # assert np.array_equal(t_v3p0, t_v3p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d955faee816db44f0a85e254d00ad008273b576d6dbe16759b0bc5b99bc5dcbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
