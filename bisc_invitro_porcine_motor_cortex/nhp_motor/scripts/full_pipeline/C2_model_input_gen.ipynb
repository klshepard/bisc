{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "During the initial phase of the decoder model building,\n",
    "I tried the following parameters:\n",
    "- using the whole spectrogram (11 uniformly spaced frequency bins) for model input\n",
    "- using normalized LMP\n",
    "- using z-scored bands\n",
    "\n",
    "They are not used any more because they do not improve the model accuracy while either\n",
    "being computationally heavier or physically less relevant (hence more difficult to justify\n",
    "their usage).\n",
    "Codes for generating these data have been commented out\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib_settings import set_plot_settings, reset_plot_settings\n",
    "\n",
    "# Set the plot settings\n",
    "set_plot_settings()\n",
    "\n",
    "# import global variables\n",
    "from utils_motor_global import *\n",
    "\n",
    "from utils_motor_sigproc import normalize_band\n",
    "# from utils_motor_sigproc import normalize_spect\n",
    "\n",
    "from utils_motor_model import make_full_t_model_input\n",
    "\n",
    "ROOT_SAVE_DIR = f'{MODEL_INPUT_DIR}/scalogram_matrix'\n",
    "\n",
    "# model input time resolution. 10 ms = T_DF_MATRIX*T_STEP_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" save M1, S1 channels.. not required for model \"\"\"\n",
    "from utils_motor_plot import draw_CS_boundary, CS_COLS\n",
    "all_chs = np.zeros((256, ))\n",
    "M1_chs, S1_chs = [], []\n",
    "\n",
    "for row, cols in enumerate(CS_COLS):\n",
    "    for col in range(cols[0]):\n",
    "        M1_chs.append(row*16 + col)\n",
    "    for col in range(cols[1], 16):\n",
    "        S1_chs.append(row*16 + col)\n",
    "\n",
    "M1_chs = np.array(M1_chs)\n",
    "S1_chs = np.array(S1_chs)\n",
    "\n",
    "all_chs[M1_chs] = -1\n",
    "all_chs[S1_chs] = 1\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.imshow(all_chs.reshape(16, -1))\n",
    "# ax.set_xticks([])\n",
    "# ax.set_yticks([])\n",
    "\n",
    "# draw_CS_boundary(ax)\n",
    "\n",
    "np.save(f'{ROOT_SAVE_DIR}/M1_channels.npy', M1_chs)\n",
    "np.save(f'{ROOT_SAVE_DIR}/S1_channels.npy', S1_chs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" load common channels \"\"\"\n",
    "common_chs = np.load(f'{ROOT_SAVE_DIR}/common_good_channels.npy') # copy-pasted manually.\n",
    "\n",
    "\"\"\" channel band mean and standard deviation \"\"\"\n",
    "spect_mu  = np.load(f'{BAND_MU_SIGMA_DIR}/spect_mu.npy')\n",
    "lmp_mu    = np.load(f'{BAND_MU_SIGMA_DIR}/lmp_mu.npy')\n",
    "lfs_mu    = np.load(f'{BAND_MU_SIGMA_DIR}/lmp_mu.npy')\n",
    "beta_mu   = np.load(f'{BAND_MU_SIGMA_DIR}/beta_mu.npy')\n",
    "lga_mu    = np.load(f'{BAND_MU_SIGMA_DIR}/lga_mu.npy')\n",
    "hga_mu    = np.load(f'{BAND_MU_SIGMA_DIR}/hga_mu.npy')\n",
    "\n",
    "spect_sigma  = np.load(f'{BAND_MU_SIGMA_DIR}/spect_sigma.npy')\n",
    "lmp_sigma    = np.load(f'{BAND_MU_SIGMA_DIR}/lmp_sigma.npy')\n",
    "lfs_sigma    = np.load(f'{BAND_MU_SIGMA_DIR}/lmp_sigma.npy')\n",
    "beta_sigma   = np.load(f'{BAND_MU_SIGMA_DIR}/beta_sigma.npy')\n",
    "lga_sigma    = np.load(f'{BAND_MU_SIGMA_DIR}/lga_sigma.npy')\n",
    "hga_sigma    = np.load(f'{BAND_MU_SIGMA_DIR}/hga_sigma.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in SESSION_KEYS:\n",
    "    load_dir = f'{REC_DIR}/6_truncate/{key}'\n",
    "    if not os.path.exists(load_dir):\n",
    "        continue\n",
    "    print(f'processing {key}...')\n",
    "\n",
    "    save_data_dir = f'{ROOT_SAVE_DIR}/{key}'\n",
    "    if not os.path.exists(save_data_dir):\n",
    "        os.makedirs(save_data_dir)\n",
    "\n",
    "    \"\"\" load data \"\"\"\n",
    "    # recording data\n",
    "    good_chs    = np.load(f'{load_dir}/good_channels_{key}.npy')\n",
    "    spect       = np.load(f'{load_dir}/spect_{key}.npy'     ) \n",
    "    lmp_data    = np.load(f'{load_dir}/lmp_{key}.npy'       ) \n",
    "    spect_t     = np.load(f'{load_dir}/spect_t_{key}.npy'   ) \n",
    "    \n",
    "    spect_f     = np.load(f'{load_dir}/spect_f_{key}.npy'   ) \n",
    "    beta_fidxs  = np.load(f'{load_dir}/beta_fidxs_{key}.npy') \n",
    "    lga_fidxs   = np.load(f'{load_dir}/lga_fidxs_{key}.npy' ) \n",
    "    hga_fidxs   = np.load(f'{load_dir}/hga_fidxs_{key}.npy' ) \n",
    "    \n",
    "    spect_lfs  = np.sum(spect[:,:,[0]], axis=2)\n",
    "    spect_beta = np.sum(spect[:,:,beta_fidxs], axis=2)\n",
    "    spect_lga  = np.sum(spect[:,:, lga_fidxs], axis=2)\n",
    "    spect_hga  = np.sum(spect[:,:, hga_fidxs], axis=2)\n",
    "    \n",
    "    # motion data has been already interpolated to model input time points\n",
    "    model_t     = np.load(f'{MODEL_INPUT_DIR}/motion/{key}/model_t_{key}.npy')\n",
    "\n",
    "    \"\"\" normalize \"\"\"\n",
    "    # norm_lmp   = normalize_band(good_chs, lmp_data, lmp_mu, lmp_sigma, sel_zscore=False)\n",
    "    norm_lfs   = normalize_band(good_chs, spect_lfs, lfs_mu, lfs_sigma, sel_zscore=False)\n",
    "    norm_beta  = normalize_band(good_chs, spect_beta, beta_mu, beta_sigma, sel_zscore=False)\n",
    "    norm_lga   = normalize_band(good_chs, spect_lga, lga_mu, lga_sigma, sel_zscore=False)\n",
    "    norm_hga   = normalize_band(good_chs, spect_hga, hga_mu, hga_sigma, sel_zscore=False)\n",
    "\n",
    "    # spectrogram is not used any more for building model input\n",
    "    # norm_spect = normalize_spect(good_chs, spect, spect_mu, spect_sigma, sel_zscore=False)\n",
    "\n",
    "    \"\"\" z-score \"\"\"\n",
    "    zs_lmp  = normalize_band(good_chs, lmp_data, lmp_mu, lmp_sigma, sel_zscore=True)\n",
    "    # zs_lfs  = normalize_band(good_chs, spect_lfs, lfs_mu, lfs_sigma, sel_zscore=True)\n",
    "    # zs_beta = normalize_band(good_chs, spect_beta, beta_mu, beta_sigma, sel_zscore=True)\n",
    "    # zs_lga  = normalize_band(good_chs, spect_lga, lga_mu, lga_sigma, sel_zscore=True)\n",
    "    # zs_hga  = normalize_band(good_chs, spect_hga, hga_mu, hga_sigma, sel_zscore=True)\n",
    "\n",
    "    # spectrogram is not used any more for building model input\n",
    "    # zs_spect = normalize_spect(good_chs, spect, spect_mu, spect_sigma, sel_zscore=True)\n",
    "\n",
    "    \"\"\" remove non-common channels \"\"\"\n",
    "    common_ch_idxs = [np.where(good_chs == ch)[0][0] for ch in common_chs]\n",
    "    assert np.array_equal(common_chs, good_chs[common_ch_idxs])\n",
    "\n",
    "    # norm_lmp    =  norm_lmp  [common_ch_idxs]\n",
    "    norm_lfs    =  norm_lfs  [common_ch_idxs]\n",
    "    norm_beta   =  norm_beta [common_ch_idxs]\n",
    "    norm_lga    =  norm_lga  [common_ch_idxs]\n",
    "    norm_hga    =  norm_hga  [common_ch_idxs]\n",
    "    # norm_spect  =  norm_spect[common_ch_idxs]\n",
    "\n",
    "    zs_lmp      =  zs_lmp    [common_ch_idxs]\n",
    "    # zs_lfs      =  zs_lfs    [common_ch_idxs]\n",
    "    # zs_beta     =  zs_beta   [common_ch_idxs]\n",
    "    # zs_lga      =  zs_lga    [common_ch_idxs]\n",
    "    # zs_hga      =  zs_hga    [common_ch_idxs]\n",
    "    # zs_spect    =  zs_spect  [common_ch_idxs]\n",
    "\n",
    "    \"\"\" check that model input matrix length matches motion data length \"\"\"\n",
    "    idx0 = np.where(spect_t >= model_t[0])[0][0]\n",
    "    idx1 = np.where(spect_t <= model_t[-1])[0][-1] + 1\n",
    "    assert len(spect_t[idx0:idx1]) == len(model_t)\n",
    "\n",
    "    \"\"\" model input params \"\"\"\n",
    "    dt = spect_t[1] - spect_t[0]\n",
    "    tau_idx0 = round(-FULL_TAU_START/dt)\n",
    "    tau_idx1 = round(FULL_TAU_END/dt)\n",
    "    # model_f_idxs = np.arange(0, len(spect_f))\n",
    "\n",
    "    \"\"\" build model input matrices \"\"\"\n",
    "    # norm_spect_matrix = make_full_t_model_input(norm_spect.astype(dtype='float16'), tau_idx0, tau_idx1, T_DF_MATRIX, model_f_idxs)\n",
    "    norm_lfs_matrix   = make_full_t_model_input(norm_lfs.astype(dtype='float16'), tau_idx0, tau_idx1, T_DF_MATRIX)\n",
    "    norm_beta_matrix  = make_full_t_model_input(norm_beta.astype(dtype='float16'), tau_idx0, tau_idx1, T_DF_MATRIX)\n",
    "    norm_lga_matrix   = make_full_t_model_input(norm_lga.astype(dtype='float16'), tau_idx0, tau_idx1, T_DF_MATRIX)\n",
    "    norm_hga_matrix   = make_full_t_model_input(norm_hga.astype(dtype='float16'), tau_idx0, tau_idx1, T_DF_MATRIX)\n",
    "\n",
    "    zs_lmp_matrix     = make_full_t_model_input(zs_lmp.astype(dtype='float16'), tau_idx0, tau_idx1, T_DF_MATRIX)\n",
    "    # zs_lfs_matrix     = make_full_t_model_input(zs_lfs.astype(dtype='float16'), tau_idx0, tau_idx1, T_DF_MATRIX)\n",
    "    # zs_beta_matrix    = make_full_t_model_input(zs_beta.astype(dtype='float16'), tau_idx0, tau_idx1, T_DF_MATRIX)\n",
    "    # zs_lga_matrix     = make_full_t_model_input(zs_lga.astype(dtype='float16'), tau_idx0, tau_idx1, T_DF_MATRIX)\n",
    "    # zs_hga_matrix     = make_full_t_model_input(zs_hga.astype(dtype='float16'), tau_idx0, tau_idx1, T_DF_MATRIX)\n",
    "\n",
    "    \"\"\" dimension check \"\"\"\n",
    "    # assert norm_spect_matrix.shape[0] == len(model_t[::T_DF_MATRIX])\n",
    "    assert zs_lmp_matrix.shape[0] == len(model_t[::T_DF_MATRIX])\n",
    "\n",
    "    \"\"\" save \"\"\"\n",
    "    # carry over:\n",
    "    np.save(f'{save_data_dir}/model_t_{key}.npy', model_t) \n",
    "    np.save(f'{save_data_dir}/spect_t_{key}.npy', spect_t) \n",
    "    np.save(f'{save_data_dir}/spect_f_{key}.npy', spect_f) \n",
    "\n",
    "    # np.save(f'{save_data_dir}/norm_spect_matrix_{key}.npy', norm_spect_matrix)\n",
    "    np.save(f'{save_data_dir}/norm_lfs_matrix_{key}.npy', norm_lfs_matrix)\n",
    "    np.save(f'{save_data_dir}/norm_beta_matrix_{key}.npy', norm_beta_matrix)\n",
    "    np.save(f'{save_data_dir}/norm_lga_matrix_{key}.npy', norm_lga_matrix)\n",
    "    np.save(f'{save_data_dir}/norm_hga_matrix_{key}.npy', norm_hga_matrix)\n",
    "    \n",
    "    np.save(f'{save_data_dir}/zs_lmp_matrix_{key}.npy', zs_lmp_matrix)\n",
    "    \n",
    "    # np.save(f'{save_data_dir}/zs_lfs_matrix_{key}.npy', zs_lfs_matrix)\n",
    "    # np.save(f'{save_data_dir}/zs_beta_matrix_{key}.npy', zs_beta_matrix)\n",
    "    # np.save(f'{save_data_dir}/zs_lga_matrix_{key}.npy', zs_lga_matrix)\n",
    "    # np.save(f'{save_data_dir}/zs_hga_matrix_{key}.npy', zs_hga_matrix)\n",
    "\n",
    "    # build this too if storage space allows\n",
    "    # zs_spect_matrix = make_full_t_model_input(zs_spect.astype(dtype='float16'), tau_idx0, tau_idx1, T_DF_MATRIX, model_f_idxs)\n",
    "    # np.save(f'{save_data_dir}/zs_spect_matrix_{key}.npy', zs_spect_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in SESSION_KEYS:\n",
    "#     fn0 = f'norm_lfs_scalo_{key}.npy'\n",
    "#     fn1 = f'norm_lfs_matrix_{key}.npy'\n",
    "# \n",
    "#     # fn0 = f'norm_beta_scalo_{key}.npy'\n",
    "#     # fn1 = f'norm_beta_matrix_{key}.npy'\n",
    "# \n",
    "#     # fn0 = f'norm_lga_scalo_{key}.npy'\n",
    "#     # fn1 = f'norm_lga_matrix_{key}.npy'\n",
    "# \n",
    "#     # fn0 = f'norm_hga_scalo_{key}.npy'\n",
    "#     # fn1 = f'norm_hga_matrix_{key}.npy'\n",
    "# \n",
    "#     # fn0 = f'zs_lmp_scalo_{key}.npy'\n",
    "#     # fn1 = f'zs_lmp_matrix_{key}.npy'\n",
    "# \n",
    "#     # fn0 = f'scalo_t_{key}.npy'\n",
    "#     # fn1 = f'model_t_{key}.npy'\n",
    "# \n",
    "#     # fn0 = f'spect_t_{key}.npy'\n",
    "#     # fn1 = f'spect_t_{key}.npy'\n",
    "#     \n",
    "#     # fn0 = f'spect_f_{key}.npy'\n",
    "#     # fn1 = f'spect_f_{key}.npy'\n",
    "# \n",
    "#     dir0 = f'./combined_preprocessed_v3/4_scalogram/{key}'\n",
    "#     dir1 = f'./model_input/scalogram_matrix/{key}'\n",
    "# \n",
    "#     X0 = np.load(f'{dir0}/{fn0}')\n",
    "#     X1 = np.load(f'{dir1}/{fn1}')\n",
    "#     assert np.allclose(X0, X1, equal_nan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d955faee816db44f0a85e254d00ad008273b576d6dbe16759b0bc5b99bc5dcbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
