{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib_settings import set_plot_settings, reset_plot_settings\n",
    "\n",
    "# Set the plot settings\n",
    "set_plot_settings()\n",
    "\n",
    "# import global variables\n",
    "from utils_motor_global import *\n",
    "from utils_motor_sigproc import get_mt_ch_psd, get_pc\n",
    "\n",
    "ROOT_SAVE_DIR = f'{REC_DIR}/3_HD_remove_{N_PC_REMOVE}_PCs'\n",
    "\n",
    "# Band-pass filter for extracting heartbeat PC\n",
    "from scipy.signal import iirfilter, sosfiltfilt\n",
    "fs = FS/RS\n",
    "Wn = [HB_BPF_LOW/(fs/2), HB_BPF_HIGH/(fs/2)]\n",
    "sos_hb = iirfilter(N=HB_BPF_N, Wn=Wn, analog=False, btype='band', ftype='butter', output='sos')\n",
    "\n",
    "N_PC_PLOT = 10 # number of PCs to plot\n",
    "\n",
    "from scipy.signal.windows import dpss\n",
    "from sklearn.utils.extmath import randomized_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in GOOD_SESSIONS:\n",
    "    keys = [key for key in SESSION_KEYS if key.startswith(f'{session:003}')]\n",
    "\n",
    "    for key in keys:\n",
    "        load_dir = f'{REC_DIR}/2_BPF_DS/{key}'\n",
    "        if not os.path.exists(load_dir):\n",
    "            continue\n",
    "\n",
    "        \"\"\" save directory \"\"\"\n",
    "        save_data_dir = f'{ROOT_SAVE_DIR}/{key}'\n",
    "        save_img_dir = f'{ROOT_SAVE_DIR}_imgs/{key}'\n",
    "        if not os.path.exists(save_data_dir):\n",
    "            os.makedirs(save_data_dir)\n",
    "        if not os.path.exists(save_img_dir):\n",
    "            os.makedirs(save_img_dir)\n",
    "\n",
    "        \"\"\" load data \"\"\"\n",
    "        good_channels = np.load(f'{load_dir}/good_channels_{key}.npy')\n",
    "        t             = np.load(f'{load_dir}/t_DS_session_{key}.npy')\n",
    "        rec_data      = np.load(f'{load_dir}/recording_DS_session_{key}.npy')\n",
    "\n",
    "        \"\"\" truncate initial data points affected by BPF artifact \"\"\"\n",
    "        t0 = t[0] + T_BPF_PAD\n",
    "        idx0 = np.where(t >= t0)[0][0]\n",
    "\n",
    "        t = t[idx0:]\n",
    "        rec_data = rec_data[idx0:,:]\n",
    "\n",
    "        \"\"\" segmentize \"\"\"\n",
    "        # recordings are partitioned to T_PC (s) long segments (last seg rounded up)\n",
    "        # two reasons for doing so\n",
    "        # 1. scipy dpss doesn't work (seems like a bug) for large dataset\n",
    "        # 2. heartbeat strength is varying in time and space. If PCs are calculated using full\n",
    "        # segments, they can become dominated by short bursts with strong HB whereas \n",
    "        # portions with weak HB become completely neglected\n",
    "        n_seg = int(np.round((t[-1] - t[0])/T_PC))\n",
    "\n",
    "        seg_start_idxs = []\n",
    "        for i_seg in range(n_seg):\n",
    "            idx = int(np.where(t >= i_seg*T_PC + t[0])[0][0])\n",
    "            seg_start_idxs.append(idx)\n",
    "\n",
    "        seg_start_idxs.append(len(t)+1)\n",
    "\n",
    "        \"\"\" initialize arrays to contain HB PCs, HB removed data \"\"\"\n",
    "        pc_removed = np.zeros_like(rec_data)\n",
    "        pc_removed_data = np.copy(rec_data)\n",
    "\n",
    "        \"\"\" iterate over segments, remove HB \"\"\"\n",
    "        for i_seg, (idx0, idx1) in enumerate(zip(seg_start_idxs[:-1], seg_start_idxs[1:])):\n",
    "            # fetch segment\n",
    "            t_seg = t[idx0:idx1]\n",
    "            rec_data_seg = rec_data[idx0:idx1, :]\n",
    "\n",
    "            \"\"\" multi-taper params \"\"\"\n",
    "            len_win = t_seg[-1] - t_seg[0] # (s)\n",
    "            assert len_win <= 1.5*T_PC\n",
    "            NW = len_win*W_MT_PC # common choices are 2.5, 3, 3.5, 4\n",
    "            K = int(2*NW - 1) # Number of tapers\n",
    "            wt = np.ones(K)/K # apply unity weight\n",
    "\n",
    "            \"\"\" params dependent on multi-taper params \"\"\"\n",
    "            n = len(t_seg)\n",
    "            half_n = int(np.ceil(n/2))\n",
    "            freq = np.fft.fftfreq(n, d = 1/fs)\n",
    "            half_freq = freq[:half_n]\n",
    "            fbin = half_freq[1]\n",
    "\n",
    "            # DPSS\n",
    "            # dpss_tapers, dpss_eigen = dpss(n, NW, K, return_ratios=True)\n",
    "            dpss_tapers = dpss(n, NW, K)\n",
    "\n",
    "            \"\"\" band-pass filter \"\"\"\n",
    "            filt_hb_data = sosfiltfilt(sos_hb, rec_data_seg, axis=0) # time * ch\n",
    "\n",
    "            \"\"\" SVD \"\"\"\n",
    "            # (ch * N_PC), (N_PC,), (N_PC * time)\n",
    "            hb_u, hb_s, hb_v = randomized_svd(filt_hb_data.T, n_components=N_PC)\n",
    "\n",
    "            \"\"\" Hemodynamics PCs \"\"\"\n",
    "            hb_pcs = np.zeros((N_PC, filt_hb_data.shape[1], filt_hb_data.shape[0])) # N * ch * time\n",
    "\n",
    "            for pc_idx in range(N_PC):\n",
    "                hb_pcs[pc_idx,:,:] = get_pc(pc_idx, hb_u, hb_s, hb_v)\n",
    "\n",
    "            hb_pcs = np.transpose(hb_pcs, (0, 2, 1)) # N * time * ch\n",
    "\n",
    "            \"\"\" get PSD of PCs \"\"\"\n",
    "            f_idx0 = np.where(half_freq > HB_FREQ_LOW)[0][0]\n",
    "            f_idx1 = np.where(half_freq < HB_FREQ_HIGH)[0][-1]\n",
    "\n",
    "            hb_pc_psds = np.zeros((N_PC, half_n))\n",
    "            hb_tones = []\n",
    "            for pc_idx, pc in enumerate(hb_v):\n",
    "                # time-series PC\n",
    "                assert len(pc) == dpss_tapers.shape[1]\n",
    "\n",
    "                # PSD of PC. hb_s[pc_idx]*pc is the time series component that is spatially \n",
    "                # distributed to channels. hb_u is excluded from computation (its\n",
    "                # columns have unit lengths)\n",
    "                hb_pc_psds[pc_idx, :] = get_mt_ch_psd(hb_s[pc_idx]*pc, dpss_tapers, wt)\n",
    "\n",
    "                # integrate the heartbeat power, which represents hemodynamics strength\n",
    "                hb_tones.append(np.sum(hb_pc_psds[pc_idx, f_idx0:f_idx1 + 1]))\n",
    "\n",
    "            \"\"\" rank PCs in terms of hemodynamics strength \"\"\"\n",
    "            pc_order = []\n",
    "            for val in reversed(sorted(hb_tones)):\n",
    "                pc_order.append(hb_tones.index(val))\n",
    "\n",
    "            \"\"\" remove PCs \"\"\"\n",
    "            pc_removed[idx0:idx1,:] = np.sum(hb_pcs[pc_order[:N_PC_REMOVE], :, :], axis=0)\n",
    "            pc_removed_data[idx0:idx1,:] -= pc_removed[idx0:idx1]\n",
    "\n",
    "            \"\"\" Plot: PSD of PCs before and after HD removal \"\"\"\n",
    "            # \"\"\" PC of recording, after removing hemodynamics \"\"\"\n",
    "            # u, s, v = randomized_svd(pc_removed_data[idx0:idx1,:].T, n_components=N_PC)\n",
    "\n",
    "            # post_pcs = np.zeros((N_PC, filt_hb_data.shape[1], filt_hb_data.shape[0]))\n",
    "            # for pc_idx in range(N_PC):\n",
    "            #     post_pcs[pc_idx,:,:] = get_pc(pc_idx, u, s, v)\n",
    "            # post_pcs = np.transpose(post_pcs, (0, 2, 1))\n",
    "            # post_pc_psds = np.zeros_like(hb_pc_psds)\n",
    "\n",
    "            # for pc_idx, pc in enumerate(v):\n",
    "            #     post_pc_psds[pc_idx, :] = get_mt_ch_psd(s[pc_idx]*pc, dpss_tapers, wt)\n",
    "\n",
    "            # \"\"\" plot: PC PSDs \"\"\"\n",
    "            # plt.close('all')\n",
    "            # fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "            # legend_strs = []\n",
    "            # for pc_idx in pc_order[:N_PC_PLOT]:\n",
    "            #     legend_strs.append(str(pc_idx))\n",
    "            #     ax.loglog(half_freq[1:], hb_pc_psds[pc_idx, 1:])\n",
    "            # ax.set_xlim((0.5, 300))\n",
    "            # ax.legend(legend_strs, title='PC', loc=(1.05, 0))\n",
    "            # ax.set_title(f'Session {session:003}. Segment: {int(t_seg[0])}-{int(t_seg[-1])} sec. PC')\n",
    "            # ax.set_xlabel('Frequency (Hz)')\n",
    "            # ax.set_ylabel('PSD (a.u.)')\n",
    "\n",
    "            # plt.savefig(f'{save_img_dir}/PC_PSD_seg_{i_seg}.png', bbox_inches='tight')\n",
    "\n",
    "            # \"\"\" PC of recording, after removing hemodynamics \"\"\"\n",
    "            # plt.close('all')\n",
    "            # fig, ax = plt.subplots(1, 1)\n",
    "            # legend_strs = []\n",
    "            # for pc_idx in range(N_PC_PLOT):\n",
    "            #     legend_strs.append(str(pc_idx))\n",
    "            #     ax.loglog(half_freq[1:], post_pc_psds[pc_idx, 1:])\n",
    "            # ax.set_xlim((0.5, 300))\n",
    "            # ax.legend(legend_strs, title='PC', loc=(1.05, 0))\n",
    "            # ax.set_title(f'Session {session:003}. Segment: {int(t_seg[0])}-{int(t_seg[-1])} sec. HB Removed')\n",
    "            # ax.set_xlabel('Frequency (Hz)')\n",
    "            # ax.set_ylabel('PSD (a.u.)')\n",
    "\n",
    "            # plt.savefig(f'{save_img_dir}/Recording_PSD_seg_{i_seg}.png', bbox_inches='tight')\n",
    "\n",
    "        \"\"\" save pc removed recording \"\"\"\n",
    "        np.save(f'{save_data_dir}/good_channels_{key}.npy', good_channels) # carry over\n",
    "        np.save(f'{save_data_dir}/t_HB_removed_session_{key}.npy', t) # truncated\n",
    "        np.save(f'{save_data_dir}/HB_PC_removed_session_{key}.npy', pc_removed)\n",
    "        np.save(f'{save_data_dir}/recording_HB_removed_session_{key}.npy', pc_removed_data)\n",
    "\n",
    "        # \"\"\" plot: channel waveforms, before and after PC removal \"\"\"\n",
    "        # # load motion data. plot together with recording data\n",
    "        # motion_dir = f'{MOTION_DIR}/{session:03}'\n",
    "        # motion_t  = np.load(f'{motion_dir}/vel_t_session_{key}.npy')\n",
    "\n",
    "        # wrist_vel_x   = np.load(f'{motion_dir}/wrist_vel_x_session_{key}.npy')\n",
    "        # wrist_vel_y   = np.load(f'{motion_dir}/wrist_vel_y_session_{key}.npy')\n",
    "        # wrist_vel_z   = np.load(f'{motion_dir}/wrist_vel_z_session_{key}.npy')\n",
    "\n",
    "        # wrist_vel_x = (wrist_vel_x - np.mean(wrist_vel_x))/np.std(wrist_vel_x)\n",
    "        # wrist_vel_y = (wrist_vel_y - np.mean(wrist_vel_y))/np.std(wrist_vel_y)\n",
    "        # wrist_vel_z = (wrist_vel_z - np.mean(wrist_vel_z))/np.std(wrist_vel_z)\n",
    "\n",
    "        # plt.close('all')\n",
    "        # fig, ax = plt.subplots(4, 1, figsize=(6, 8), sharex=True)\n",
    "\n",
    "        # y_offset = 5\n",
    "\n",
    "        # for ch_idx, ch in enumerate(good_channels):\n",
    "        #     for ii in range(4):\n",
    "        #         ax[ii].clear()\n",
    "        #     ax[0].set_title(f'Session {key}, Channel {ch}')\n",
    "\n",
    "        #     ax[0].plot(t, rec_data[:, ch_idx])\n",
    "        #     ax[1].plot(t, pc_removed[:, ch_idx])\n",
    "        #     ax[2].plot(t, pc_removed_data[:, ch_idx])\n",
    "\n",
    "        #     ax[0].set_ylabel('Raw')\n",
    "        #     ax[1].set_ylabel(f'First {N_PC_REMOVE} PCs\\n BPF {HB_BPF_LOW:d}-{HB_BPF_HIGH:d} Hz')\n",
    "        #     ax[2].set_ylabel(f'PC Removed')\n",
    "\n",
    "        #     ax[-1].plot(motion_t, wrist_vel_x + y_offset)\n",
    "        #     ax[-1].plot(motion_t, wrist_vel_y)\n",
    "        #     ax[-1].plot(motion_t, wrist_vel_z - y_offset)\n",
    "        #     ax[-1].set_ylabel(f'Wrist Vel.')\n",
    "        #     ax[-1].legend(['x', 'y', 'z'], fontsize=8)\n",
    "        #     ax[-1].set_xlabel('Time (s)')\n",
    "\n",
    "        #     for ii in range(4):\n",
    "        #         for idx in seg_start_idxs[1:-1]:\n",
    "        #             ax[ii].axvline(x=t[idx], color='k')\n",
    "        #         ax[ii].grid(True)\n",
    "\n",
    "        #     plt.savefig(f'{save_img_dir}/channel_{ch}.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" write assertion check \"\"\"\n",
    "key = SESSION_KEYS[0]\n",
    "# fn = f'good_channels_{key}.npy'\n",
    "# fn = f'HB_PC_removed_session_{key}.npy'\n",
    "fn = f'recording_HB_removed_session_{key}.npy'\n",
    "# fn = f't_HB_removed_session_{key}.npy'\n",
    "dir0 = f'./recording_preprocessed_v2/3_SVD_remove_5_PCs/{key}'\n",
    "dir1 = f'./recording_preprocessed_v3/3_HD_remove_5_PCs/{key}'\n",
    "\n",
    "X0 = np.load(f'{dir0}/{fn}')\n",
    "X1 = np.load(f'{dir1}/{fn}')\n",
    "\n",
    "np.allclose(X0, X1, equal_nan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d955faee816db44f0a85e254d00ad008273b576d6dbe16759b0bc5b99bc5dcbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
